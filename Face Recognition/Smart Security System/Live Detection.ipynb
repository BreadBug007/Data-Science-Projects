{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import imutils\n",
    "import face_recognition\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find path of xml file containing haarcascade file\n",
    "cascPathface = os.path.dirname(\n",
    "    cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "# load the harcaascade in the cascade classifier\n",
    "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
    "# load the known faces and embeddings saved in last file\n",
    "data = pickle.loads(open('face_enc_live', \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained faces\n",
    "names = sorted(list(set(data['names'])))\n",
    "for name in names:\n",
    "    print(name, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spreadsheet_service():\n",
    "  SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "  \"\"\"Shows basic usage of the Sheets API.\n",
    "    Prints values from a sample spreadsheet.\n",
    "  \"\"\"\n",
    "  creds = None\n",
    "  # The file token.pickle stores the user's access and refresh tokens, and is\n",
    "  # created automatically when the authorization flow completes for the first\n",
    "  # time.\n",
    "  token_file = Path(FILEDIR, 'token.pickle')\n",
    "  creds_file = Path(FILEDIR, 'credentials.json')\n",
    "  if os.path.exists(token_file):\n",
    "    with open(token_file, 'rb') as token:\n",
    "      creds = pickle.load(token)\n",
    "  # If there are no (valid) credentials available, let the user log in.\n",
    "  if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "      creds.refresh(Request())\n",
    "    else:\n",
    "      flow = InstalledAppFlow.from_client_secrets_file(\n",
    "          creds_file, SCOPES)\n",
    "      creds = flow.run_local_server(port=0)\n",
    "    # Save the credentials for the next run\n",
    "    with open(token_file, 'wb') as token:\n",
    "      pickle.dump(creds, token)\n",
    "\n",
    "  service = build('sheets', 'v4', credentials=creds)\n",
    "  return service\n",
    "\n",
    "\n",
    "def create_new_spreadsheet(spreadsheet_name):\n",
    "  # Create spreadsheets service\n",
    "  service = init_spreadsheet_service()\n",
    "  spreadsheet = {\n",
    "      'properties': {\n",
    "          'title': spreadsheet_name\n",
    "      }\n",
    "  }\n",
    "  spreadsheet = service.spreadsheets().create(body=spreadsheet,\n",
    "                                              fields='spreadsheetId').execute()\n",
    "  return spreadsheet.get('spreadsheetId')\n",
    "\n",
    "\n",
    "def get_data(spreadsheet_id, range_name='Sheet1'):\n",
    "  service = init_spreadsheet_service()\n",
    "  result = service.spreadsheets().values().get(\n",
    "      spreadsheetId=spreadsheet_id, range=range_name).execute()\n",
    "  rows = result.get('values', [])\n",
    "  return rows\n",
    "\n",
    "\n",
    "def initiate_header(spreadsheet_id, range_name='Sheet1'):\n",
    "  prev_data = get_data(spreadsheet_id)\n",
    "  if len(prev_data) > 0:\n",
    "    return\n",
    "  elif len(prev_data) == 0:\n",
    "    data = [['Person', 'Recorded Time']]\n",
    "    service = init_spreadsheet_service()\n",
    "\n",
    "    body = {\n",
    "        'values': [i for i in data]\n",
    "    }\n",
    "\n",
    "    service.spreadsheets().values().update(\n",
    "        spreadsheetId=spreadsheet_id, range=range_name,\n",
    "        valueInputOption='RAW', body=body).execute()\n",
    "    return\n",
    "\n",
    "\n",
    "def check_for_new_run(config_file, spreadsheet_name):\n",
    "  config = configparser.ConfigParser()\n",
    "  config.read(config_file)\n",
    "\n",
    "  current_date = datetime.today().strftime(\"%d-%m-%Y\")\n",
    "  config_date = config['base']['current_date']\n",
    "  if config_date.strip() == current_date.strip():\n",
    "    print(\n",
    "        \"Script already run today, not creating a new spreadsheet\")\n",
    "    spreadsheet_id = config['base']['spreadsheet_id']\n",
    "    print(f\"Spreadsheet ID: {spreadsheet_id}\")\n",
    "  else:\n",
    "    print(\n",
    "        f\"Script last run on {config_date}. Date today: {current_date}\")\n",
    "    print(\"Creating new spreadsheet\")\n",
    "    spreadsheet_id = create_new_spreadsheet(spreadsheet_name)\n",
    "    config['base']['spreadsheet_id'] = spreadsheet_id\n",
    "    config['base']['current_date'] = current_date\n",
    "    print(f\"Spreadsheet ID: {spreadsheet_id}\")\n",
    "  \n",
    "  # check if header exists and create otherwise\n",
    "  initiate_header(spreadsheet_id)\n",
    "  with open(config_file, 'w') as conf:\n",
    "    config.write(conf)\n",
    "  return spreadsheet_id\n",
    "\n",
    "\n",
    "def upload_data(spreadsheet_id, data, range_name='Sheet1'):\n",
    "  service = init_spreadsheet_service()\n",
    "\n",
    "  body = {\n",
    "      'values': [i for i in data]\n",
    "  }\n",
    "\n",
    "  service.spreadsheets().values().append(\n",
    "      spreadsheetId=spreadsheet_id, range=range_name,\n",
    "      valueInputOption='RAW', body=body).execute()\n",
    "\n",
    "\n",
    "def upload_faces(spreadsheet_id, faces):\n",
    "#   prev_entries = get_spreadsheet_data(spreadsheet_id)\n",
    "  current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#   prev_data = get_data(spreadsheet_id)\n",
    "  all_data = [[i, current_time] for i in faces]\n",
    "  print(\"Uploading faces -\", \", \".join(faces), \"- at time\", current_time)\n",
    "  upload_data(spreadsheet_id, all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEDIR = os.path.abspath('')\n",
    "CONFIG_FILE = Path(FILEDIR, 'smart_security_config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate spreadsheet\n",
    "spreadsheet_name = \"Smart Security %s\" % (datetime.today().strftime(\"%d-%m-%Y\"))\n",
    "spreadsheet_id = check_for_new_run(CONFIG_FILE, spreadsheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Streaming started\")\n",
    "try:\n",
    "  video_capture = cv2.VideoCapture(0)\n",
    "  # loop over frames from the video file stream\n",
    "  while True:\n",
    "    # grab the frame from the threaded video stream\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # convert the input frame from BGR to RGB \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # the facial embeddings for face in input\n",
    "    encodings = face_recognition.face_encodings(rgb)\n",
    "    names = []\n",
    "    # loop over the facial embeddings incase\n",
    "    # we have multiple embeddings for multiple fcaes\n",
    "    for encoding in encodings:\n",
    "     #Compare encodings with encodings in data[\"encodings\"]\n",
    "     #Matches contain array with boolean values and True for the embeddings it matches closely\n",
    "     #and False for rest\n",
    "      matches = face_recognition.compare_faces(data[\"encodings\"],\n",
    "       encoding)\n",
    "      #set name =inknown if no encoding matches\n",
    "      name = \"Unknown\"\n",
    "      # check to see if we have found a match\n",
    "      if True in matches:\n",
    "        #Find positions at which we get True and store them\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "        counts = {}\n",
    "        # loop over the matched indexes and maintain a count for\n",
    "        # each recognized face face\n",
    "        for i in matchedIdxs:\n",
    "          #Check the names at respective indexes we stored in matchedIdxs\n",
    "          name = data[\"names\"][i]\n",
    "          #increase count for the name we got\n",
    "          counts[name] = counts.get(name, 0) + 1\n",
    "        #set name which has highest count\n",
    "        name = max(counts, key=counts.get)\n",
    "\n",
    "      # update the list of names\n",
    "      names.append(name)\n",
    "      upload_faces(spreadsheet_id, names)\n",
    "finally:\n",
    "  video_capture.release()\n",
    "  cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
