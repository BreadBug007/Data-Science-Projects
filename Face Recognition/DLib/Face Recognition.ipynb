{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = \"dataset/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image:  1  of  64\n",
      "Working on image:  2  of  64\n",
      "Working on image:  3  of  64\n",
      "Working on image:  4  of  64\n",
      "Working on image:  5  of  64\n",
      "More than one face found. Skipping the image...\n",
      "Working on image:  6  of  64\n",
      "Working on image:  7  of  64\n",
      "More than one face found. Skipping the image...\n",
      "Working on image:  8  of  64\n",
      "Working on image:  9  of  64\n",
      "Working on image:  10  of  64\n",
      "Working on image:  11  of  64\n",
      "Working on image:  12  of  64\n",
      "Working on image:  13  of  64\n",
      "Working on image:  14  of  64\n",
      "Working on image:  15  of  64\n",
      "Working on image:  16  of  64\n",
      "Working on image:  17  of  64\n",
      "Working on image:  18  of  64\n",
      "Working on image:  19  of  64\n",
      "Working on image:  20  of  64\n",
      "Working on image:  21  of  64\n",
      "Working on image:  22  of  64\n",
      "Working on image:  23  of  64\n",
      "Working on image:  24  of  64\n",
      "Working on image:  25  of  64\n",
      "Working on image:  26  of  64\n",
      "Working on image:  27  of  64\n",
      "Working on image:  28  of  64\n",
      "Working on image:  29  of  64\n",
      "Working on image:  30  of  64\n",
      "Working on image:  31  of  64\n",
      "Working on image:  32  of  64\n",
      "Working on image:  33  of  64\n",
      "Working on image:  34  of  64\n",
      "Working on image:  35  of  64\n",
      "Working on image:  36  of  64\n",
      "Working on image:  37  of  64\n",
      "Working on image:  38  of  64\n",
      "Working on image:  39  of  64\n",
      "Working on image:  40  of  64\n",
      "Working on image:  41  of  64\n",
      "Working on image:  42  of  64\n",
      "Working on image:  43  of  64\n",
      "Working on image:  44  of  64\n",
      "Working on image:  45  of  64\n",
      "Working on image:  46  of  64\n",
      "Working on image:  47  of  64\n",
      "Working on image:  48  of  64\n",
      "Working on image:  49  of  64\n",
      "Working on image:  50  of  64\n",
      "Working on image:  51  of  64\n",
      "Working on image:  52  of  64\n",
      "Working on image:  53  of  64\n",
      "Working on image:  54  of  64\n",
      "Working on image:  55  of  64\n",
      "Working on image:  56  of  64\n",
      "Working on image:  57  of  64\n",
      "Working on image:  58  of  64\n",
      "Working on image:  59  of  64\n",
      "Working on image:  60  of  64\n",
      "Working on image:  61  of  64\n",
      "Working on image:  62  of  64\n",
      "Working on image:  63  of  64\n",
      "Working on image:  64  of  64\n",
      "\n",
      "Total faces saved: 8\n"
     ]
    }
   ],
   "source": [
    "# get paths of each file in folder named Images\n",
    "# Images here contains my data(folders of various persons)\n",
    "\n",
    "imagePaths = list(paths.list_images(training_dataset))\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    print(\"Working on image: \", i+1, \" of \", len(imagePaths))\n",
    "    # extract the person name from the image path\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "    # load the input image and convert it from BGR (OpenCV ordering)\n",
    "    # to dlib ordering (RGB)\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Use Face_recognition to locate faces\n",
    "    boxes = face_recognition.face_locations(rgb,model='hog')\n",
    "    # compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "    if len(encodings) > 1:\n",
    "        print(\"More than one face found. Skipping the image...\")\n",
    "        continue\n",
    "    # loop over the encodings\n",
    "    for encoding in encodings:\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    "\n",
    "print(f\"\\nTotal faces saved: {len(list(set(knownNames)))}\")\n",
    "# save emcodings along with their names in dictionary data\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "# use pickle to save data into a file for later use\n",
    "f = open(\"face_enc_small\", \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = 'dataset/testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find path of xml file containing haarcascade file\n",
    "cascPathface = os.path.dirname(\n",
    " cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "# load the harcaascade in the cascade classifier\n",
    "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
    "# load the known faces and embeddings saved earlier\n",
    "data = pickle.loads(open('face_enc_small', \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_face(image):\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #convert image to Greyscale for haarcascade\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    encodings = face_recognition.face_encodings(rgb)\n",
    "\n",
    "    if len(encodings) > 1:\n",
    "        print(\"Found more than one encoding. Most likely, the image has multiple faces\")\n",
    "        return None, None\n",
    "    elif len(encodings) == 0:\n",
    "        print(\"No encoding match found for the given face.\")\n",
    "        return None, None\n",
    "    \n",
    "    names = []\n",
    "    matches = face_recognition.compare_faces(data[\"encodings\"], encodings[0])\n",
    "\n",
    "    if True in matches:\n",
    "        #Find positions at which we get True and store them\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "        counts = {}\n",
    "        # loop over the matched indexes and maintain a count for\n",
    "        # each recognized face face\n",
    "        for i in matchedIdxs:\n",
    "            #Check the names at respective indexes we stored in matchedIdxs\n",
    "            name = data[\"names\"][i]\n",
    "            #increase count for the name we got\n",
    "            counts[name] = counts.get(name, 0) + 1\n",
    "            #set name which has highest count\n",
    "            name = max(counts, key=counts.get)\n",
    "\n",
    "\n",
    "        # update the list of names\n",
    "        names.append(name)\n",
    "        if len(names) > 1:\n",
    "            print(\"Found more than one match for facial encoding\")\n",
    "            return None, None\n",
    "        \n",
    "        # loop over the recognized faces\n",
    "        for ((x, y, w, h), name) in zip(faces, names):\n",
    "            # rescale the face coordinates\n",
    "            # draw the predicted face name on the image\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(image, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "             0.75, (0, 255, 0), 2)\n",
    "    else:\n",
    "        print(\"No encoding matches found. Possibly a new face\")\n",
    "        return None, None\n",
    "#     cv2.imshow(\"Frame\", image)\n",
    "#     cv2.waitKey(0)\n",
    "    if len(names) == 0:\n",
    "        return None\n",
    "    return names[0], image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_mapping = {0: 'Arnold_Schwarzenegger', \n",
    "#                    1: 'Donald_Rumsfeld', \n",
    "#                    2: 'George_W_Bush', \n",
    "#                    3: 'Gerhard_Schroeder', \n",
    "#                    4: 'Hugo_Chavez', \n",
    "#                    5: 'Jacques_Chirac', \n",
    "#                    6: 'Tony_Blair', \n",
    "#                    7: 'Vladimir_Putin'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arnold_Schwarzenegger \n",
      "\n",
      "Donald_Rumsfeld \n",
      "\n",
      "George_W_Bush \n",
      "\n",
      "Gerhard_Schroeder \n",
      "\n",
      "Hugo_Chavez \n",
      "\n",
      "Jacques_Chirac \n",
      "\n",
      "Tony_Blair \n",
      "\n",
      "Vladimir_Putin \n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = sorted(list(set(data['names'])))\n",
    "for name in names:\n",
    "    print(name, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_status = {'correct': 0, 'incorrect': 0, 'unidentified': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No encoding matches found. Possibly a new face\n",
      "Face could not be recognized for Ariel_Sharon_0002.jpg\n",
      "\n",
      "No encoding matches found. Possibly a new face\n",
      "Face could not be recognized for Colin_Powell_0002.jpg\n",
      "\n",
      "Original face: Arnold_Schwarzenegger; Identified face: Arnold_Schwarzenegger\n",
      "\n",
      "Original face: Arnold_Schwarzenegger; Identified face: Arnold_Schwarzenegger\n",
      "\n",
      "Original face: Donald_Rumsfeld; Identified face: Donald_Rumsfeld\n",
      "\n",
      "Original face: Donald_Rumsfeld; Identified face: Donald_Rumsfeld\n",
      "\n",
      "Original face: George_W_Bush; Identified face: George_W_Bush\n",
      "\n",
      "Original face: George_W_Bush; Identified face: George_W_Bush\n",
      "\n",
      "Original face: Gerhard_Schroeder; Identified face: Gerhard_Schroeder\n",
      "\n",
      "Original face: Gerhard_Schroeder; Identified face: Gerhard_Schroeder\n",
      "\n",
      "Original face: Hugo_Chavez; Identified face: Hugo_Chavez\n",
      "\n",
      "Original face: Hugo_Chavez; Identified face: Hugo_Chavez\n",
      "\n",
      "Original face: Jacques_Chirac; Identified face: Jacques_Chirac\n",
      "\n",
      "Original face: Jacques_Chirac; Identified face: Jacques_Chirac\n",
      "\n",
      "Original face: Tony_Blair; Identified face: Tony_Blair\n",
      "\n",
      "Original face: Tony_Blair; Identified face: Tony_Blair\n",
      "\n",
      "Original face: Vladimir_Putin; Identified face: Vladimir_Putin\n",
      "\n",
      "Original face: Vladimir_Putin; Identified face: Vladimir_Putin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on validation dataset\n",
    "\n",
    "imagePaths = list(paths.list_images(testing_dataset))\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    try:\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "    except ValueError:\n",
    "        name = \"Unknown\"\n",
    "    image = cv2.imread(imagePath)\n",
    "    pred_name, pred_image = identify_face(image)\n",
    "    if pred_name is None:\n",
    "        print(f\"Face could not be recognized for {imagePath.split(os.path.sep)[-1]}\")\n",
    "    else:\n",
    "        print(f\"Original face: {name}; Identified face: {pred_name}\")\n",
    "        if pred_name != name:\n",
    "            print(\"Wrong face match found.\")\n",
    "    if pred_name == name:\n",
    "        prediction_status['correct'] += 1\n",
    "    elif pred_name == None:\n",
    "        prediction_status['unidentified'] += 1\n",
    "    elif pred_name != name:\n",
    "        prediction_status['incorrect'] += 1\n",
    "    print()\n",
    "#     cv2.imshow(\"Frame\", pred_image)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': 16, 'incorrect': 0, 'unidentified': 2}\n"
     ]
    }
   ],
   "source": [
    "print(prediction_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
